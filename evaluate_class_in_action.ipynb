{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "81a79b96",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ddrnet_23_slim import DualResNet_imagenet, DualResNet\n",
    "import numpy as np\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "import sys\n",
    "from Utility import *\n",
    "from Dataset_helper import *\n",
    "import tf2onnx \n",
    "import onnx\n",
    "import onnxruntime as rt \n",
    "import time\n",
    "from threading import Thread\n",
    "from queue import Queue\n",
    "\n",
    "import time\n",
    "import cv2\n",
    "from datetime import timedelta\n",
    "from timeit import default_timer as timer\n",
    "from imutils.video import FileVideoStream\n",
    "from imutils.video import FPS\n",
    "import imutils\n",
    "\n",
    "from evaulate_model import Evaluate\n",
    "import pandas as pd\n",
    "import focal_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b64608bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"onnx_final/ddrnet336_600.onnx\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "04c08db3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# load onnx model\n",
    "\n",
    "providers = ['CPUExecutionProvider']\n",
    "sess_options = rt.SessionOptions()\n",
    "\n",
    "sess_options.graph_optimization_level = rt.GraphOptimizationLevel.ORT_ENABLE_ALL\n",
    "\n",
    "\n",
    "sess = rt.InferenceSession(model_name, sess_options=sess_options,\n",
    "                           providers=providers) \n",
    "\n",
    "\n",
    "output_names = [n.name for n in onnx.load(model_name).graph.output]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a505db63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# onnx model for evaulate object\n",
    "class Onnx_model:\n",
    "    def __init__(self, model=None, names=None):\n",
    "        self.sess = model\n",
    "        self.names = names\n",
    "        \n",
    "    def get_predict(self, frame):\n",
    "        if frame is not None:\n",
    "            pred_img = self.sess.run(self.names, {'input': frame})[0]\n",
    "            return np.uint8(((np.argmax(pred_img[0,:,:,:], axis=-1)/12)+0)*255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "983c7230",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tensorflow model and tf model func for evaluate object\n",
    "class UpdatedMeanIoU(tf.keras.metrics.MeanIoU):\n",
    "    def __init__(self,\n",
    "               y_true=None,\n",
    "               y_pred=None,\n",
    "               num_classes=None,\n",
    "               name=None,\n",
    "               dtype=None):\n",
    "        super(UpdatedMeanIoU, self).__init__(num_classes = num_classes,name=name, dtype=dtype)\n",
    "\n",
    "    def update_state(self, y_true, y_pred, sample_weight=None):\n",
    "        y_pred = tf.math.argmax(y_pred, axis=-1)\n",
    "        return super().update_state(y_true, y_pred, sample_weight)\n",
    "    \n",
    "    def get_config(self):\n",
    "        config = super().get_config().copy()\n",
    "        return config\n",
    "\n",
    "\n",
    "tf_model = tf.keras.models.load_model('saved_model_final/ddrnet336_600_tf', \n",
    "                                      custom_objects={'UpdatedMeanIoU': UpdatedMeanIoU})\n",
    "\n",
    "\n",
    "class TF:\n",
    "    def __init__(self, model=None, names=None):\n",
    "        self.model = model\n",
    "        self.names = names\n",
    "        \n",
    "    def get_predict(self, frame):\n",
    "        if frame is not None:\n",
    "            with tf.device('/GPU:0'):\n",
    "                pred_img = self.model.predict(frame)\n",
    "            return np.uint8(((np.argmax(pred_img[0,:,:,:], axis=-1)/12)+0)*255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0ab6c679",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_func(img=None):\n",
    "    if img is not None:\n",
    "        \n",
    "        frame = cv2.resize(img, (600, 336), cv2.INTER_NEAREST)/255\n",
    "        frame = np.expand_dims(frame, 0).astype('float32')\n",
    "        \n",
    "        \n",
    "        return frame\n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "de5d33a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save CPU, RAM, GPU usage as csv\n",
    "def make_dataframe(gpu, cpu, memory, t1, t2, t1_m, t2_m):\n",
    "      \n",
    "    time = [[t1[i] ,t2[i], t1_m[i], t2_m[i]]  for i in range(len(eval_his.t1)-1)]\n",
    "    time = pd.DataFrame(time, columns=['t1', 't2', 't1_model', 't2_model'])\n",
    "    cpu = pd.DataFrame(cpu, columns=['cpu0', 'cpu1', 'cpu2', 'cpu3', 'cpu4', 'cpu5', 'cpu6', 'cpu7'])\n",
    "    gpu = pd.DataFrame(gpu)\n",
    "    memory = pd.DataFrame(memory, columns=['total', 'available', 'percent', 'used', 'free'])\n",
    "    \n",
    "    return pd.concat([gpu, cpu, memory, time], axis=1)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0cfdd97e",
   "metadata": {},
   "outputs": [],
   "source": [
    "size = ['336_600', '400_720','720_1280','1080_1920']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ccacf76a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Press \"q\" to release video\n",
      "[INFO] Starting video file read thread...\n",
      "[INFO] Starting video file show thread...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-10-bb074275d500>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     32\u001b[0m                         onnx_model, transform_func, meas=True, max_num_f=400)\n\u001b[0;32m     33\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 34\u001b[1;33m         \u001b[0meval_his\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstart_evaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     35\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     36\u001b[0m         df = make_dataframe(eval_his.gpu, eval_his.cpu, eval_his.memory, eval_his.t1, eval_his.t2, \n",
      "\u001b[1;32mD:\\VUT_FSI\\Magister\\00_Diplomka\\DDRNet-Tensorflow\\evaulate_model.py\u001b[0m in \u001b[0;36mstart_evaluate\u001b[1;34m(self, main_loop_transform)\u001b[0m\n\u001b[0;32m    136\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    137\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mt1_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 138\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mframe\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel_definition\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mframe\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    139\u001b[0m             \u001b[1;31m# self.frame = np.uint8(((np.argmax(pred_img[0,:,:,:], axis=-1)/12)+0)*255)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    140\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mt2_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-4-e336f102a7f5>\u001b[0m in \u001b[0;36mget_predict\u001b[1;34m(self, frame)\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget_predict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mframe\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mframe\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m             \u001b[0mpred_img\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnames\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;34m'input'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mframe\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0muint8\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpred_img\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m/\u001b[0m\u001b[1;36m12\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;36m255\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\danis\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\onnxruntime\\capi\\onnxruntime_inference_collection.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, output_names, input_feed, run_options)\u001b[0m\n\u001b[0;32m    190\u001b[0m             \u001b[0moutput_names\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0moutput\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0moutput\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_outputs_meta\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    191\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 192\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput_names\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_feed\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrun_options\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    193\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mC\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mEPFail\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    194\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_enable_fallback\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# test every model on cpu/cuda for every resolutin (size)\n",
    "\n",
    "for k in size:\n",
    "    \n",
    "    model_name = f\"onnx_final/ddrnet{k}.onnx\"\n",
    "    sess = rt.InferenceSession(model_name, sess_options=sess_options,\n",
    "                           providers=providers) \n",
    "    onnx_model = Onnx_model(model=sess, names=output_names).get_predict\n",
    "\n",
    "#     tf_model = tf.keras.models.load_model(f'saved_model_final/ddrnet{k}_tf', \n",
    "#                                       custom_objects={'UpdatedMeanIoU': UpdatedMeanIoU})\n",
    "\n",
    "\n",
    "\n",
    "#     tff = TF(model=tf_model).get_predict\n",
    "    \n",
    "    x1 = int(k.split('_')[0])\n",
    "    x2 = int(k.split('_')[1])\n",
    "    \n",
    "    \n",
    "    def transform_func(img=None):\n",
    "        if img is not None:\n",
    "\n",
    "            frame = cv2.resize(img, (x2, x1), cv2.INTER_NEAREST)/255\n",
    "            frame = np.expand_dims(frame, 0).astype('float32')\n",
    "\n",
    "            return frame\n",
    "        else:\n",
    "            return None\n",
    "    \n",
    "\n",
    "    for i in range(1, 2):\n",
    "        eval_his = Evaluate('IMG_7677k.mp4', \n",
    "                        onnx_model, transform_func, meas=True, max_num_f=400)\n",
    "\n",
    "        eval_his.start_evaluate()\n",
    "\n",
    "        df = make_dataframe(eval_his.gpu, eval_his.cpu, eval_his.memory, eval_his.t1, eval_his.t2, \n",
    "                   eval_his.t1_model, eval_his.t2_model)\n",
    "\n",
    "        df.to_csv(f'test_obm_vyk_tf/gpu/1050ti/{k}/his{i}.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
